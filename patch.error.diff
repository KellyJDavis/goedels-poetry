diff --git a/goedels_poetry/agents/formalizer_agent.py b/goedels_poetry/agents/formalizer_agent.py
index e6f6403..8b936e3 100644
--- a/goedels_poetry/agents/formalizer_agent.py
+++ b/goedels_poetry/agents/formalizer_agent.py
@@ -3,13 +3,14 @@ from __future__ import annotations
 import re
 from functools import partial
 from hashlib import sha256
+from typing import cast
 
 from langchain_core.language_models.chat_models import BaseChatModel
 from langgraph.graph import END, START, StateGraph
 from langgraph.graph.state import CompiledStateGraph
 
 from goedels_poetry.agents.state import InformalTheoremState
-from goedels_poetry.agents.util.common import load_prompt, remove_default_imports
+from goedels_poetry.agents.util.common import LLMParsingError, load_prompt, remove_default_imports
 from goedels_poetry.agents.util.debug import log_llm_response
 
 
@@ -146,7 +147,7 @@ def _normalize_informal_statement(informal_statement: str) -> str:
     return informal_statement.strip().lower()
 
 
-def _parser_formalizer_response(response: str) -> str | None:
+def _parser_formalizer_response(response: str) -> str:
     """
     Extract the final lean code snippet from the passed string.
 
@@ -158,9 +159,16 @@ def _parser_formalizer_response(response: str) -> str | None:
     Returns
     -------
     str
-        A string containing the lean code snippet if found, otherwise None.
+        A string containing the lean code snippet if found.
+
+    Raises
+    ------
+    LLMParsingError
+        If no code block is found in the response.
     """
     pattern = r"```lean4?\n(.*?)\n?```"
     matches = re.findall(pattern, response, re.DOTALL)
-    formal_statement = matches[-1].strip() if matches else None
+    if not matches:
+        raise LLMParsingError("Failed to extract code block from LLM response", response)  # noqa: TRY003
+    formal_statement = cast(str, matches[-1]).strip()
     return formal_statement
diff --git a/goedels_poetry/agents/proof_sketcher_agent.py b/goedels_poetry/agents/proof_sketcher_agent.py
index 1475e58..9031514 100644
--- a/goedels_poetry/agents/proof_sketcher_agent.py
+++ b/goedels_poetry/agents/proof_sketcher_agent.py
@@ -1,5 +1,6 @@
 import re
 from functools import partial
+from typing import cast
 
 from langchain_core.language_models.chat_models import BaseChatModel
 from langchain_core.messages import AIMessage, HumanMessage
@@ -8,7 +9,7 @@ from langgraph.graph.state import CompiledStateGraph
 from langgraph.types import Send
 
 from goedels_poetry.agents.state import DecomposedFormalTheoremState, DecomposedFormalTheoremStates
-from goedels_poetry.agents.util.common import add_default_imports, load_prompt, remove_default_imports
+from goedels_poetry.agents.util.common import LLMParsingError, add_default_imports, load_prompt, remove_default_imports
 from goedels_poetry.agents.util.debug import log_llm_response
 
 
@@ -142,12 +143,19 @@ def _parse_proof_sketcher_response(response: str) -> str:
     Returns
     -------
     str
-        A string containing the lean code snippet if found, otherwise empty string.
+        A string containing the lean code snippet if found.
+
+    Raises
+    ------
+    LLMParsingError
+        If no code block is found in the response.
     """
     # TODO: Figure out if this algorithm works for the non-Goedel LLM
     pattern = r"```lean4?\n(.*?)\n?```"
     matches = re.findall(pattern, response, re.DOTALL)
-    proof_sketch = matches[-1].strip() if matches else ""
+    if not matches:
+        raise LLMParsingError("Failed to extract code block from LLM response", response)  # noqa: TRY003
+    proof_sketch = cast(str, matches[-1]).strip()
     # Remove DEFAULT_IMPORTS if present
     if proof_sketch:
         proof_sketch = remove_default_imports(proof_sketch)
diff --git a/goedels_poetry/agents/prover_agent.py b/goedels_poetry/agents/prover_agent.py
index 329d208..47381c0 100644
--- a/goedels_poetry/agents/prover_agent.py
+++ b/goedels_poetry/agents/prover_agent.py
@@ -1,5 +1,6 @@
 import re
 from functools import partial
+from typing import cast
 
 from langchain_core.language_models.chat_models import BaseChatModel
 from langchain_core.messages import AIMessage, HumanMessage
@@ -8,7 +9,7 @@ from langgraph.graph.state import CompiledStateGraph
 from langgraph.types import Send
 
 from goedels_poetry.agents.state import FormalTheoremProofState, FormalTheoremProofStates
-from goedels_poetry.agents.util.common import add_default_imports, load_prompt, remove_default_imports
+from goedels_poetry.agents.util.common import LLMParsingError, add_default_imports, load_prompt, remove_default_imports
 from goedels_poetry.agents.util.debug import log_llm_response
 
 
@@ -142,11 +143,18 @@ def _parse_prover_response(response: str) -> str:
     Returns
     -------
     str
-        A string containing the lean code snippet if found, otherwise empty string.
+        A string containing the lean code snippet if found.
+
+    Raises
+    ------
+    LLMParsingError
+        If no code block is found in the response.
     """
     pattern = r"```lean4?\n(.*?)\n?```"
     matches = re.findall(pattern, response, re.DOTALL)
-    formal_proof = matches[-1].strip() if matches else ""
+    if not matches:
+        raise LLMParsingError("Failed to extract code block from LLM response", response)  # noqa: TRY003
+    formal_proof = cast(str, matches[-1]).strip()
     # Remove DEFAULT_IMPORTS if present
     if formal_proof:
         formal_proof = remove_default_imports(formal_proof)
diff --git a/goedels_poetry/agents/util/common.py b/goedels_poetry/agents/util/common.py
index 8c4ed49..f2867d5 100644
--- a/goedels_poetry/agents/util/common.py
+++ b/goedels_poetry/agents/util/common.py
@@ -5,6 +5,30 @@ from typing import Any
 
 from jinja2 import Environment, FileSystemLoader, select_autoescape
 
+
+class LLMParsingError(Exception):
+    """
+    Exception raised when the LLM returns a response that cannot be parsed.
+
+    This typically occurs when the LLM fails to return code in the expected format
+    (e.g., missing code blocks or malformed responses).
+    """
+
+    def __init__(self, message: str, response: str) -> None:
+        """
+        Initialize the LLMParsingError.
+
+        Parameters
+        ----------
+        message : str
+            A short description of what failed to parse
+        response : str
+            The full LLM response that failed to parse
+        """
+        self.response = response
+        super().__init__(f"{message}: {response}")
+
+
 # Create Environment for loading prompts
 _env = Environment(
     loader=FileSystemLoader(os.path.join(os.path.dirname(__file__), "../../data/prompts")),
diff --git a/goedels_poetry/agents/util/kimina_server.py b/goedels_poetry/agents/util/kimina_server.py
index 9579680..df5a267 100644
--- a/goedels_poetry/agents/util/kimina_server.py
+++ b/goedels_poetry/agents/util/kimina_server.py
@@ -5,6 +5,8 @@ from typing import cast
 
 from kimina_client.models import AstModuleResponse, CheckResponse, CommandResponse, Message
 
+from goedels_poetry.agents.util.common import LLMParsingError
+
 
 def parse_kimina_check_response(check_response: CheckResponse) -> dict:
     """
@@ -45,7 +47,7 @@ def parse_kimina_check_response(check_response: CheckResponse) -> dict:
     return parsed_response
 
 
-def parse_semantic_check_response(response: str) -> str | None:
+def parse_semantic_check_response(response: str) -> str:
     """
     Parses the passed symantic response into a string used by  Goedel-Prover-V2
 
@@ -58,10 +60,17 @@ def parse_semantic_check_response(response: str) -> str | None:
     -------
     str:
         The parsed judgement string.
+
+    Raises
+    ------
+    LLMParsingError
+        If no judgement is found in the response.
     """
     pattern = r"Judgement:\s*(.+)"
     matches = re.findall(pattern, response, re.IGNORECASE)
-    return matches[-1].strip() if matches else None
+    if not matches:
+        raise LLMParsingError("Failed to extract judgement from LLM response", response)  # noqa: TRY003
+    return cast(str, matches[-1]).strip()
 
 
 def parse_kimina_ast_code_response(ast_code_response: AstModuleResponse) -> dict:
